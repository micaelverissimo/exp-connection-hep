{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "363aa200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "repo_path = '/home/micael.verissimo/paper_lzt/exp-connection-hep/'\n",
    "sys.path.insert(0, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c76cc49e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 17:11:26.690283: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-09 17:11:26.690324: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-09 17:11:26.699042: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-09 17:11:26.769738: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 17:11:37.546644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/02\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.callbacks import sp_index\n",
    "from src.decorators import Summary\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2eacce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "sgn_df = pd.concat([pd.read_parquet(os.path.join(repo_path, f'data/processed/{iname}')) for iname in ['zee_avg250_100k.parquet']], axis=0)\n",
    "bkg_df = pd.concat([pd.read_parquet(os.path.join(repo_path, f'data/processed/{iname}')) for iname in ['jf17_avg250_100k.parquet']], axis=0)\n",
    "\n",
    "m_df = pd.concat([sgn_df, bkg_df], axis=0)\n",
    "m_df = m_df.loc[m_df.cl_eta.abs() <= 2.5]\n",
    "m_df = m_df.loc[m_df.cl_et >= 15000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f482f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing et bin = [15.0, 30[ and eta bin = [0.0, 0.8[\n",
      "Number of events in this bin: 37640\n",
      "Processing et bin = [15.0, 30[ and eta bin = [0.8, 1.37[\n",
      "Number of events in this bin: 26467\n",
      "Processing et bin = [15.0, 30[ and eta bin = [1.37, 1.54[\n",
      "Number of events in this bin: 6577\n",
      "Processing et bin = [15.0, 30[ and eta bin = [1.54, 2.37[\n",
      "Number of events in this bin: 42118\n",
      "Processing et bin = [15.0, 30[ and eta bin = [2.37, 2.5[\n",
      "Number of events in this bin: 4836\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.0, 0.8[\n",
      "Number of events in this bin: 38431\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.8, 1.37[\n",
      "Number of events in this bin: 28745\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.37, 1.54[\n",
      "Number of events in this bin: 6052\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.54, 2.37[\n",
      "Number of events in this bin: 23096\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [2.37, 2.5[\n",
      "Number of events in this bin: 3065\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.0, 0.8[\n",
      "Number of events in this bin: 8796\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.8, 1.37[\n",
      "Number of events in this bin: 6779\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.37, 1.54[\n",
      "Number of events in this bin: 940\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.54, 2.37[\n",
      "Number of events in this bin: 1418\n",
      "Processing et bin = [50.0, inf[ and eta bin = [2.37, 2.5[\n",
      "Number of events in this bin: 117\n"
     ]
    }
   ],
   "source": [
    "GeV = 1e3\n",
    "#et_bins  = [3., 7., 10., 15., 20., 30., 40., 50., 1000000.]\n",
    "et_bins  = [[15., 30], [30., 50.], [50., np.inf]]\n",
    "eta_bins = [[0.0, 0.8], [0.8, 1.37], [1.37, 1.54], [1.54, 2.37], [2.37, 2.50]]\n",
    "tot = 0\n",
    "for iet, (l_iet, h_iet) in enumerate(et_bins):\n",
    "    for ieta, (l_ieta, h_ieta) in enumerate(eta_bins):\n",
    "        print(f'Processing et bin = [{l_iet}, {h_iet}[ and eta bin = [{l_ieta}, {h_ieta}[')\n",
    "        m_df.loc[(m_df.cl_et >= l_iet*GeV) & (m_df.cl_et < h_iet*GeV), 'et_bin'] = iet\n",
    "        m_df.loc[(m_df.cl_eta.abs() >= l_ieta) & (m_df.cl_eta.abs() < h_ieta), 'eta_bin'] = ieta\n",
    "        l_samples = len(m_df.loc[(m_df.et_bin == iet) & (m_df.eta_bin == ieta)])\n",
    "        print(f'Number of events in this bin: {l_samples}')\n",
    "        #display(m_df.loc[(m_df.et_bin == iet) & (m_df.eta_bin == ieta), 'target'].value_counts().to_frame('Samples'))\n",
    "        tot += l_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62c318d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EventNumber",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "RunNumber",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "avgmu",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_deta",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_dphi",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e0",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e233",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e237",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e277",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e2tsts1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_e3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ehad1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ehad2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ehad3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_emaxs1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_emaxs2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_eratio",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_et",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_eta",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_etot",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_f0",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_f1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_f2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_f3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_fracMax",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_lambdaCenter",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_lateralMom",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_longitudinalMom",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_phi",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_reta",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_rhad",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_rhad1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_0",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_1",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_10",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_11",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_12",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_13",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_14",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_15",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_16",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_17",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_18",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_19",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_20",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_21",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_22",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_23",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_24",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_25",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_26",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_27",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_28",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_29",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_3",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_30",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_31",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_32",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_33",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_34",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_35",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_36",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_37",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_38",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_39",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_4",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_40",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_41",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_42",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_43",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_44",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_45",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_46",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_47",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_48",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_49",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_5",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_50",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_51",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_52",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_53",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_54",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_55",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_56",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_57",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_58",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_59",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_6",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_60",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_61",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_62",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_63",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_64",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_65",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_66",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_67",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_68",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_69",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_7",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_70",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_71",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_72",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_73",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_74",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_75",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_76",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_77",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_78",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_79",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_8",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_80",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_81",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_82",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_83",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_84",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_85",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_86",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_87",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_88",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_89",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_9",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_90",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_91",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_92",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_93",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_94",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_95",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_96",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_97",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_98",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_ring_99",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_rphi",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_secondLambda",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_secondR",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "cl_weta2",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "el_et",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "el_eta",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "el_loose",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "el_medium",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "el_phi",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "el_tight",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "el_vloose",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "mc_e_float",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mc_et_float",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mc_eta_float",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mc_pdgid_float",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "mc_phi_float",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "seed_eta",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "seed_phi",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "target",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "et_bin",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "eta_bin",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8dd820b9-d581-41db-a235-1b4c2d9aee9b",
       "rows": [
        [
         "1",
         "11106",
         "0",
         "227.0",
         "0.2",
         "0.2",
         "36484.445",
         "-296.27386",
         "19247.932",
         "17715.184",
         "12524.038",
         "13534.753",
         "15929.817",
         "2483.5212",
         "-182.39684",
         "2094.4226",
         "-374.5618",
         "-382.3729",
         "8056.999",
         "8195.375",
         "0.5287668",
         "22971.533",
         "1.0374999",
         "37821.934",
         "-0.008120553",
         "0.5275654",
         "0.48555443",
         "-0.004999304",
         "0.0",
         "4.5729e-41",
         "0.0",
         "0.0",
         "-1.3376001",
         "0.84964895",
         "0.036659125",
         "0.057405904",
         "1548.4613",
         "689.8136",
         "0.70441437",
         "-67.3336",
         "34.62694",
         "-824.65",
         "673.6034",
         "-482.1919",
         "572.0417",
         "-198.6069",
         "95.012245",
         "-20.845608",
         "1021.4675",
         "138.94052",
         "-97.89871",
         "-58.439632",
         "-128.09424",
         "2.8581429",
         "28.429773",
         "2841.174",
         "3027.5134",
         "544.95056",
         "159.16417",
         "0.0",
         "88.6954",
         "-0.7922821",
         "28.240404",
         "126.358154",
         "140.40387",
         "-174.20474",
         "-84.40791",
         "15.38921",
         "107.048965",
         "194.01709",
         "5692.9707",
         "22.938187",
         "-70.171364",
         "134.36183",
         "-39.56132",
         "-47.87527",
         "-111.850624",
         "2.1378574",
         "-296.67804",
         "45.15029",
         "40.951046",
         "4852.6963",
         "-14.929405",
         "-186.05478",
         "45.61856",
         "55.26301",
         "-211.74014",
         "-60.309856",
         "226.993",
         "-32.772144",
         "7.9690704",
         "-210.90198",
         "32.23366",
         "-26.47229",
         "-84.952965",
         "33.42479",
         "133.91614",
         "197.44427",
         "113.88849",
         "285.206",
         "267.6084",
         "246.05363",
         "327.27945",
         "0.0",
         "332.31158",
         "251.9891",
         "341.46115",
         "1019.9094",
         "544.28955",
         "365.73322",
         "261.77545",
         "106.6071",
         "-51.96533",
         "70.3322",
         "55.354813",
         "144.76215",
         "55.09635",
         "373.50226",
         "162.06819",
         "43.45067",
         "-59.702614",
         "96.68862",
         "107.21942",
         "109.38946",
         "0.0",
         "70.88721",
         "5160.016",
         "2725.4363",
         "1241.6272",
         "902.73956",
         "536.4834",
         "-247.7532",
         "499.95416",
         "-500.35474",
         "84.03281",
         "27.17539",
         "0.9253245",
         "0.0",
         "-0.45685935",
         "0.012121198",
         "22971.533",
         "1.0374999",
         "True",
         "False",
         "-1.3376001",
         "False",
         "True",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0236121",
         "-1.3333457",
         "1",
         "0.0",
         "1.0"
        ],
        [
         "5",
         "11157",
         "0",
         "255.0",
         "0.2",
         "0.2",
         "39841.965",
         "-802.1952",
         "28068.957",
         "13365.143",
         "19251.87",
         "19006.703",
         "19368.832",
         "7578.308",
         "-789.94104",
         "-947.50525",
         "2036.3523",
         "0.0",
         "27950.898",
         "10684.795",
         "0.573404",
         "17519.133",
         "1.4625001",
         "40930.812",
         "-0.020134429",
         "0.70450735",
         "0.3354539",
         "-0.01982686",
         "3.0799e-41",
         "3.0799e-41",
         "-2.0420406e-13",
         "3.0799e-41",
         "-1.8285002",
         "0.9813035",
         "0.02732915",
         "-0.02378159",
         "60.26004",
         "-109.57573",
         "2288.511",
         "1227.1284",
         "859.9888",
         "403.74432",
         "-381.74066",
         "-170.00774",
         "-186.04202",
         "-174.36119",
         "-354.15414",
         "-275.66742",
         "-181.22896",
         "-381.45004",
         "-370.92984",
         "-263.75583",
         "-284.13028",
         "-334.67343",
         "-354.37805",
         "-287.737",
         "-365.27405",
         "-178.66496",
         "-137.73874",
         "-12.085089",
         "-286.37912",
         "-412.72263",
         "-299.51147",
         "-33.01835",
         "-36.278984",
         "6.119301",
         "99.70797",
         "100.50935",
         "184.04108",
         "27.229172",
         "-37.825466",
         "-78.758255",
         "-90.16085",
         "-12.814507",
         "-160.88652",
         "-169.58043",
         "-264.18076",
         "-365.27017",
         "-108.31852",
         "30.615185",
         "182.00854",
         "35.984444",
         "-40.782806",
         "-235.98044",
         "-135.70427",
         "145.04338",
         "265.27948",
         "107.89707",
         "246.38383",
         "-45.479774",
         "-20.02163",
         "83.07139",
         "-36.456276",
         "-62.471924",
         "124.532906",
         "-88.49254",
         "-157.69884",
         "93.82384",
         "-54.03883",
         "-198.78986",
         "-90.88924",
         "-34.454132",
         "0.0",
         "50.858566",
         "0.0",
         "0.0",
         "4678.5967",
         "3786.751",
         "530.2112",
         "-478.78024",
         "-585.3288",
         "-502.2679",
         "-501.80832",
         "131.8623",
         "7431.735",
         "40.17789",
         "-1.8080665",
         "-104.62982",
         "41.13133",
         "39.986687",
         "11.118994",
         "5.4313393",
         "-15.305135",
         "269.20105",
         "89.28152",
         "6472.7866",
         "-218.49582",
         "-203.3363",
         "330.80948",
         "66.951996",
         "251.91707",
         "129.8092",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.0128989",
         "-2.042039e-13",
         "-2.042039e-13",
         "0.011962308",
         "17519.133",
         "1.4625001",
         "True",
         "False",
         "-1.8285002",
         "False",
         "True",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.4540182",
         "-1.8228729",
         "1",
         "0.0",
         "2.0"
        ],
        [
         "6",
         "11158",
         "0",
         "285.0",
         "0.2",
         "0.2",
         "179719.52",
         "0.0",
         "16250.172",
         "163441.25",
         "128326.375",
         "137872.42",
         "148983.42",
         "2983.8694",
         "28.093178",
         "-2341.647",
         "-225.05078",
         "-5566.694",
         "8331.521",
         "65284.473",
         "0.4725999",
         "36544.957",
         "2.2755",
         "171586.14",
         "0.0",
         "0.09041963",
         "0.90942407",
         "0.00015631679",
         "3.0799e-41",
         "3.0799e-41",
         "-8.373879e-14",
         "3.0799e-41",
         "3.1293",
         "0.92542124",
         "-0.04525603",
         "-0.013029453",
         "0.0",
         "0.0",
         "630.0928",
         "0.0",
         "20.98705",
         "0.0",
         "114.57385",
         "139.03627",
         "0.0",
         "265.4103",
         "0.0",
         "167.31596",
         "0.0",
         "0.0",
         "129.42825",
         "0.0",
         "175.425",
         "0.0",
         "178.82352",
         "-5.6080093",
         "0.0",
         "-103.20111",
         "0.0",
         "0.0",
         "-22.423376",
         "0.0",
         "-320.13052",
         "0.0",
         "-153.88583",
         "0.0",
         "-169.86772",
         "0.0",
         "-32.0074",
         "-100.34723",
         "0.0",
         "0.0",
         "14.460026",
         "0.0",
         "12.866035",
         "0.0",
         "-148.93538",
         "0.0",
         "-128.53978",
         "0.0",
         "-42.483063",
         "0.0",
         "65.08883",
         "0.0",
         "0.23131752",
         "0.0",
         "902.5531",
         "0.0",
         "152.76877",
         "0.0",
         "112.855865",
         "0.0",
         "0.0",
         "66.68828",
         "0.0",
         "-54.73735",
         "-87.412094",
         "0.0",
         "-5.451481",
         "0.0",
         "-23.51726",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "13275.231",
         "12819.22",
         "2987.1047",
         "1213.3845",
         "638.18787",
         "965.0626",
         "985.4607",
         "324.5531",
         "1302.6871",
         "132.77548",
         "44.3787",
         "-79.18668",
         "79.634796",
         "3.890051",
         "-19.332958",
         "-40.423107",
         "-4.2250037",
         "423.19144",
         "-34.57858",
         "266.55072",
         "-91.9273",
         "15.339662",
         "892.8956",
         "151.34833",
         "-416.27875",
         "-681.50446",
         "394.93634",
         "-1803.3768",
         "164.57227",
         "0.0",
         "0.93076175",
         "-8.373871e-14",
         "-8.373871e-14",
         "0.011643858",
         "36544.957",
         "2.2755",
         "True",
         "False",
         "3.1293",
         "False",
         "False",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "2.275902",
         "3.1403604",
         "1",
         "1.0",
         "3.0"
        ],
        [
         "10",
         "11125",
         "0",
         "239.0",
         "0.2",
         "0.2",
         "39832.59",
         "-1573.2687",
         "31329.984",
         "10756.3955",
         "9683.039",
         "9946.333",
         "11609.538",
         "4922.041",
         "-680.51855",
         "-595.2697",
         "-103.38054",
         "-64.57643",
         "15735.8125",
         "5604.9277",
         "0.5234702",
         "21317.416",
         "1.2375",
         "39069.363",
         "-0.03949702",
         "0.78654146",
         "0.27004007",
         "-0.017084466",
         "3.0799e-41",
         "3.0799e-41",
         "-2.101483e-13",
         "3.0799e-41",
         "-2.0003",
         "0.85673803",
         "-0.01916086",
         "-0.014944289",
         "75.56016",
         "14.962088",
         "1489.8109",
         "693.1515",
         "234.41599",
         "49.90854",
         "146.21724",
         "36.131004",
         "33.710182",
         "-183.68369",
         "19.02498",
         "135.52211",
         "-331.0298",
         "112.735756",
         "203.19131",
         "55.05124",
         "-88.04116",
         "107.812775",
         "294.5318",
         "177.83272",
         "140.4794",
         "127.595024",
         "15.105389",
         "-144.09409",
         "240.09091",
         "146.99255",
         "42.80094",
         "499.4273",
         "313.14682",
         "134.20587",
         "-43.31124",
         "-42.99085",
         "-6.4567566",
         "-58.795734",
         "-77.300385",
         "-387.31207",
         "-239.98112",
         "-172.28584",
         "-322.82263",
         "-93.7893",
         "-69.4439",
         "195.97327",
         "71.06656",
         "84.42913",
         "85.7286",
         "13.636429",
         "188.48145",
         "365.70425",
         "973.3761",
         "957.06903",
         "946.3968",
         "299.57468",
         "16.36194",
         "-100.418846",
         "-110.2422",
         "-88.46902",
         "-133.68483",
         "43.442932",
         "-189.44461",
         "-133.83646",
         "-13.003435",
         "-92.26963",
         "-142.3997",
         "37.672188",
         "-313.62225",
         "-74.11485",
         "0.0",
         "-13.118355",
         "0.0",
         "0.0",
         "2999.6184",
         "2182.5037",
         "704.7539",
         "326.26013",
         "573.7748",
         "-60.28476",
         "-398.04883",
         "-476.03534",
         "6269.4976",
         "44.03823",
         "-60.132534",
         "-43.475082",
         "-181.86462",
         "-67.22685",
         "-79.3766",
         "-61.860237",
         "0.4045787",
         "164.68504",
         "-207.62192",
         "3809.6343",
         "0.0",
         "0.0",
         "50.980568",
         "19.229614",
         "-121.92094",
         "0.0",
         "22.030437",
         "-0.9222678",
         "-16.755747",
         "-43.599094",
         "0.97352856",
         "-2.1014814e-13",
         "-2.1014814e-13",
         "0.011908051",
         "21317.416",
         "1.2375",
         "True",
         "False",
         "-2.0003",
         "False",
         "True",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "1.2267085",
         "-1.9978836",
         "1",
         "0.0",
         "1.0"
        ],
        [
         "14",
         "11146",
         "0",
         "244.0",
         "0.2",
         "0.2",
         "98000.62",
         "91.565575",
         "58963.348",
         "39396.113",
         "34765.38",
         "36291.254",
         "39575.23",
         "9133.44",
         "-450.41776",
         "6090.4727",
         "1130.5587",
         "158.66159",
         "34299.953",
         "17942.809",
         "0.5794277",
         "36286.19",
         "-1.6505",
         "105380.32",
         "0.00093433674",
         "0.60166305",
         "0.40199864",
         "-0.0045960704",
         "3.0865e-41",
         "3.0865e-41",
         "-2962.8281",
         "3.0865e-41",
         "0.6994999",
         "0.91701937",
         "0.07530251",
         "0.06214729",
         "46.95888",
         "-54.231598",
         "1705.4857",
         "856.8403",
         "612.73694",
         "446.3191",
         "615.0275",
         "437.13248",
         "133.7855",
         "-19.83958",
         "-89.98216",
         "-115.14935",
         "59.926907",
         "-173.72687",
         "-132.44708",
         "-130.71307",
         "-158.78937",
         "-1.3137474",
         "293.8643",
         "116.4176",
         "281.84027",
         "149.02507",
         "1.6104679",
         "-9.11174",
         "177.86858",
         "120.67204",
         "130.9071",
         "108.403595",
         "-82.74641",
         "-23.149918",
         "-84.906235",
         "-58.560963",
         "95.15466",
         "108.363625",
         "-0.07858077",
         "9.872864",
         "-29.750631",
         "-154.33534",
         "-111.10029",
         "-82.100716",
         "65.76239",
         "13.393273",
         "-157.15088",
         "-141.05292",
         "-108.41506",
         "-10.458759",
         "-45.159657",
         "-17.95118",
         "37.575203",
         "-36.69588",
         "172.4545",
         "-38.184128",
         "-55.473175",
         "-29.928415",
         "87.720985",
         "145.28949",
         "50.67752",
         "366.75363",
         "173.92023",
         "819.1213",
         "-42.202465",
         "130.89333",
         "72.211235",
         "48.739212",
         "34.897873",
         "281.2433",
         "0.0",
         "17.0174",
         "0.0",
         "0.0",
         "6643.593",
         "6228.8086",
         "952.34357",
         "828.5757",
         "-688.86017",
         "-748.54065",
         "-961.7979",
         "2288.1362",
         "9705.368",
         "127.215385",
         "23.860556",
         "-116.95285",
         "-84.96276",
         "157.72559",
         "22.892204",
         "-87.80036",
         "-35.16202",
         "509.85144",
         "117.01529",
         "5208.293",
         "225.83034",
         "68.7753",
         "341.42062",
         "173.1637",
         "-120.28276",
         "0.0",
         "243.55354",
         "35.647358",
         "-227.11868",
         "0.0",
         "0.95795476",
         "-2962.8252",
         "-2962.8252",
         "0.012563124",
         "36286.19",
         "-1.6505",
         "True",
         "False",
         "0.6994999",
         "False",
         "True",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "0.0",
         "-1.6626842",
         "0.7083703",
         "1",
         "1.0",
         "3.0"
        ]
       ],
       "shape": {
        "columns": 156,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventNumber</th>\n",
       "      <th>RunNumber</th>\n",
       "      <th>avgmu</th>\n",
       "      <th>cl_deta</th>\n",
       "      <th>cl_dphi</th>\n",
       "      <th>cl_e</th>\n",
       "      <th>cl_e0</th>\n",
       "      <th>cl_e1</th>\n",
       "      <th>cl_e2</th>\n",
       "      <th>cl_e233</th>\n",
       "      <th>...</th>\n",
       "      <th>mc_e_float</th>\n",
       "      <th>mc_et_float</th>\n",
       "      <th>mc_eta_float</th>\n",
       "      <th>mc_pdgid_float</th>\n",
       "      <th>mc_phi_float</th>\n",
       "      <th>seed_eta</th>\n",
       "      <th>seed_phi</th>\n",
       "      <th>target</th>\n",
       "      <th>et_bin</th>\n",
       "      <th>eta_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11106</td>\n",
       "      <td>0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>36484.445312</td>\n",
       "      <td>-296.273865</td>\n",
       "      <td>19247.931641</td>\n",
       "      <td>17715.183594</td>\n",
       "      <td>12524.038086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.023612</td>\n",
       "      <td>-1.333346</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11157</td>\n",
       "      <td>0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>39841.964844</td>\n",
       "      <td>-802.195190</td>\n",
       "      <td>28068.957031</td>\n",
       "      <td>13365.142578</td>\n",
       "      <td>19251.869141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.454018</td>\n",
       "      <td>-1.822873</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11158</td>\n",
       "      <td>0</td>\n",
       "      <td>285.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>179719.515625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16250.171875</td>\n",
       "      <td>163441.250000</td>\n",
       "      <td>128326.375000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.275902</td>\n",
       "      <td>3.140360</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11125</td>\n",
       "      <td>0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>39832.589844</td>\n",
       "      <td>-1573.268677</td>\n",
       "      <td>31329.984375</td>\n",
       "      <td>10756.395508</td>\n",
       "      <td>9683.039062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.226709</td>\n",
       "      <td>-1.997884</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11146</td>\n",
       "      <td>0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>98000.617188</td>\n",
       "      <td>91.565575</td>\n",
       "      <td>58963.347656</td>\n",
       "      <td>39396.113281</td>\n",
       "      <td>34765.378906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.662684</td>\n",
       "      <td>0.708370</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 156 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    EventNumber  RunNumber  avgmu  cl_deta  cl_dphi           cl_e  \\\n",
       "1         11106          0  227.0      0.2      0.2   36484.445312   \n",
       "5         11157          0  255.0      0.2      0.2   39841.964844   \n",
       "6         11158          0  285.0      0.2      0.2  179719.515625   \n",
       "10        11125          0  239.0      0.2      0.2   39832.589844   \n",
       "14        11146          0  244.0      0.2      0.2   98000.617188   \n",
       "\n",
       "          cl_e0         cl_e1          cl_e2        cl_e233  ...  mc_e_float  \\\n",
       "1   -296.273865  19247.931641   17715.183594   12524.038086  ...         0.0   \n",
       "5   -802.195190  28068.957031   13365.142578   19251.869141  ...         0.0   \n",
       "6      0.000000  16250.171875  163441.250000  128326.375000  ...         0.0   \n",
       "10 -1573.268677  31329.984375   10756.395508    9683.039062  ...         0.0   \n",
       "14    91.565575  58963.347656   39396.113281   34765.378906  ...         0.0   \n",
       "\n",
       "    mc_et_float  mc_eta_float  mc_pdgid_float  mc_phi_float  seed_eta  \\\n",
       "1           0.0           0.0             0.0           0.0  1.023612   \n",
       "5           0.0           0.0             0.0           0.0  1.454018   \n",
       "6           0.0           0.0             0.0           0.0  2.275902   \n",
       "10          0.0           0.0             0.0           0.0  1.226709   \n",
       "14          0.0           0.0             0.0           0.0 -1.662684   \n",
       "\n",
       "    seed_phi  target  et_bin  eta_bin  \n",
       "1  -1.333346       1     0.0      1.0  \n",
       "5  -1.822873       1     0.0      2.0  \n",
       "6   3.140360       1     1.0      3.0  \n",
       "10 -1.997884       1     0.0      1.0  \n",
       "14  0.708370       1     1.0      3.0  \n",
       "\n",
       "[5 rows x 156 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19628bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating reference for et_bin=0 and eta_bin=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating reference for et_bin=0 and eta_bin=1\n",
      "Creating reference for et_bin=0 and eta_bin=2\n",
      "Creating reference for et_bin=0 and eta_bin=3\n",
      "Creating reference for et_bin=0 and eta_bin=4\n",
      "Creating reference for et_bin=1 and eta_bin=0\n",
      "Creating reference for et_bin=1 and eta_bin=1\n",
      "Creating reference for et_bin=1 and eta_bin=2\n",
      "Creating reference for et_bin=1 and eta_bin=3\n",
      "Creating reference for et_bin=1 and eta_bin=4\n",
      "Creating reference for et_bin=2 and eta_bin=0\n",
      "Creating reference for et_bin=2 and eta_bin=1\n",
      "Creating reference for et_bin=2 and eta_bin=2\n",
      "Creating reference for et_bin=2 and eta_bin=3\n",
      "Creating reference for et_bin=2 and eta_bin=4\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import json\n",
    "for iet_bin, ieta_bin in itertools.product(range(len(et_bins)), range(len(eta_bins))):\n",
    "    print(f'Creating reference for et_bin={iet_bin} and eta_bin={ieta_bin}')\n",
    "    references = {}\n",
    "    aux_df = m_df.loc[(m_df.et_bin == iet_bin) & (m_df.eta_bin == ieta_bin)]\n",
    "    for iop, target_eff in zip(['tight', 'medium', 'loose'], [0.90, 0.95, 0.99]):\n",
    "        key = iop\n",
    "        references[key] = {}\n",
    "        references[key]['det'] = {}\n",
    "        references[key]['det']['passed'] = np.ceil(target_eff*len(aux_df.loc[aux_df.target == 1]))\n",
    "        references[key]['det']['total'] = len(aux_df.loc[aux_df.target == 1])\n",
    "    with open(os.path.join(repo_path, f'data/processed/references_et{iet_bin}_eta{ieta_bin}.json'), 'w') as f:\n",
    "        json.dump(references, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429d5335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class SequentialCuts:\n",
    "    \"\"\"\n",
    "    A class to create sequential cuts on three variables to achieve a target efficiency for a given class.\n",
    "    \n",
    "    This class optimizes cut thresholds on three variables to maintain a specified efficiency level\n",
    "    while maximizing background rejection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_efficiency=0.9, optimization_method='nelder-mead', verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize the SequentialCuts class.\n",
    "        \n",
    "        Args:\n",
    "            target_efficiency (float): Target efficiency for the signal class (0-1).\n",
    "            optimization_method (str): Optimization method for finding cuts ('nelder-mead', 'powell', 'bfgs').\n",
    "            verbose (bool): Whether to print optimization progress.\n",
    "        \"\"\"\n",
    "        self.target_efficiency = target_efficiency\n",
    "        self.optimization_method = optimization_method\n",
    "        self.verbose = verbose\n",
    "        self.cuts = None\n",
    "        self.efficiency_achieved = None\n",
    "        self.background_rejection = None\n",
    "        self.variable_names = None\n",
    "        \n",
    "    def _calculate_efficiency(self, df, label_column, cuts, variable_names, signal_class=1):\n",
    "        \"\"\"\n",
    "        Calculate efficiency for given cuts.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            label_column (str): Name of the label column.\n",
    "            cuts (tuple): Tuple of three cut values (cut1, cut2, cut3).\n",
    "            variable_names (list): List of three variable names to apply cuts on.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            float: Efficiency for the signal class.\n",
    "        \"\"\"\n",
    "        if len(variable_names) != 3:\n",
    "            raise ValueError(\"Must provide exactly 3 variable names\")\n",
    "            \n",
    "        # Apply cuts sequentially\n",
    "        mask = (df[variable_names[0]] > cuts[0]) & \\\n",
    "               (df[variable_names[1]] > cuts[1]) & \\\n",
    "               (df[variable_names[2]] > cuts[2])\n",
    "        \n",
    "        # Calculate efficiency for signal class\n",
    "        signal_mask = df[label_column] == signal_class\n",
    "        signal_total = signal_mask.sum()\n",
    "        \n",
    "        if signal_total == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        signal_passed = (mask & signal_mask).sum()\n",
    "        efficiency = signal_passed / signal_total\n",
    "        \n",
    "        return efficiency\n",
    "    \n",
    "    def _calculate_background_rejection(self, df, label_column, cuts, variable_names, signal_class=1):\n",
    "        \"\"\"\n",
    "        Calculate background rejection for given cuts.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            label_column (str): Name of the label column.\n",
    "            cuts (tuple): Tuple of three cut values.\n",
    "            variable_names (list): List of three variable names.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            float: Background rejection rate.\n",
    "        \"\"\"\n",
    "        # Apply cuts\n",
    "        mask = (df[variable_names[0]] > cuts[0]) & \\\n",
    "               (df[variable_names[1]] > cuts[1]) & \\\n",
    "               (df[variable_names[2]] > cuts[2])\n",
    "        \n",
    "        # Calculate background rejection\n",
    "        background_mask = df[label_column] != signal_class\n",
    "        background_total = background_mask.sum()\n",
    "        \n",
    "        if background_total == 0:\n",
    "            return 1.0\n",
    "            \n",
    "        background_passed = (mask & background_mask).sum()\n",
    "        background_rejection = 1.0 - (background_passed / background_total)\n",
    "        \n",
    "        return background_rejection\n",
    "    \n",
    "    def _objective_function(self, cuts, df, label_column, variable_names, signal_class=1):\n",
    "        \"\"\"\n",
    "        Objective function to minimize. Minimizes the deviation from target efficiency\n",
    "        while maximizing background rejection.\n",
    "        \n",
    "        Args:\n",
    "            cuts (tuple): Tuple of three cut values.\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            label_column (str): Name of the label column.\n",
    "            variable_names (list): List of three variable names.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            float: Objective function value to minimize.\n",
    "        \"\"\"\n",
    "        efficiency = self._calculate_efficiency(df, label_column, cuts, variable_names, signal_class)\n",
    "        background_rejection = self._calculate_background_rejection(df, label_column, cuts, variable_names, signal_class)\n",
    "        \n",
    "        # Penalize deviation from target efficiency heavily\n",
    "        efficiency_penalty = 1000 * (efficiency - self.target_efficiency) ** 2\n",
    "        \n",
    "        # Maximize background rejection (minimize negative rejection)\n",
    "        rejection_reward = -background_rejection\n",
    "        \n",
    "        return efficiency_penalty + rejection_reward\n",
    "    \n",
    "    def optimize_cuts(self, df, variable_names, label_column, signal_class=1, initial_cuts=None):\n",
    "        \"\"\"\n",
    "        Optimize cuts to achieve target efficiency.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            variable_names (list): List of three variable names to apply cuts on.\n",
    "            label_column (str): Name of the label column.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            initial_cuts (tuple): Initial guess for cuts. If None, uses data percentiles.\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Optimized cut values (cut1, cut2, cut3).\n",
    "        \"\"\"\n",
    "        if len(variable_names) != 3:\n",
    "            raise ValueError(\"Must provide exactly 3 variable names\")\n",
    "            \n",
    "        # Check if columns exist\n",
    "        missing_cols = [col for col in variable_names + [label_column] if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "            \n",
    "        self.variable_names = variable_names\n",
    "        \n",
    "        if initial_cuts is None:\n",
    "            # Use 25th percentile as initial guess for cuts\n",
    "            initial_cuts = tuple(df[var].quantile(0.25) for var in variable_names)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Starting optimization with initial cuts: {dict(zip(variable_names, initial_cuts))}\")\n",
    "            print(f\"Target efficiency: {self.target_efficiency}\")\n",
    "        \n",
    "        # Optimize cuts\n",
    "        result = optimize.minimize(\n",
    "            self._objective_function,\n",
    "            initial_cuts,\n",
    "            args=(df, label_column, variable_names, signal_class),\n",
    "            method=self.optimization_method,\n",
    "            options={'maxiter': 1000}\n",
    "        )\n",
    "        \n",
    "        if not result.success:\n",
    "            print(f\"Warning: Optimization did not converge: {result.message}\")\n",
    "        \n",
    "        self.cuts = tuple(result.x)\n",
    "        self.efficiency_achieved  = self._calculate_efficiency(df, label_column, self.cuts, variable_names, signal_class)\n",
    "        self.background_rejection = self._calculate_background_rejection(df, label_column, self.cuts, variable_names, signal_class)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Optimized cuts: {dict(zip(variable_names, self.cuts))}\")\n",
    "            print(f\"Achieved efficiency: {self.efficiency_achieved:.4f}\")\n",
    "            print(f\"Background rejection: {self.background_rejection:.4f}\")\n",
    "            print(f\"False Alarm: {1.0-self.background_rejection:.4f}\")\n",
    "        \n",
    "        return self.cuts\n",
    "    \n",
    "    def apply_cuts(self, df):\n",
    "        \"\"\"\n",
    "        Apply the optimized cuts to data.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            \n",
    "        Returns:\n",
    "            pd.Series: Boolean mask indicating which samples pass the cuts.\n",
    "        \"\"\"\n",
    "        if self.cuts is None:\n",
    "            raise ValueError(\"Cuts have not been optimized yet. Call optimize_cuts() first.\")\n",
    "            \n",
    "        if self.variable_names is None:\n",
    "            raise ValueError(\"Variable names not set. Call optimize_cuts() first.\")\n",
    "            \n",
    "        # Check if columns exist\n",
    "        missing_cols = [col for col in self.variable_names if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "            \n",
    "        mask = (df[self.variable_names[0]] > self.cuts[0]) & \\\n",
    "               (df[self.variable_names[1]] > self.cuts[1]) & \\\n",
    "               (df[self.variable_names[2]] > self.cuts[2])\n",
    "        return mask\n",
    "    \n",
    "    def evaluate_cuts(self, df, label_column, signal_class=1):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the cuts on new data.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            label_column (str): Name of the label column.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing efficiency, background rejection, and other metrics.\n",
    "        \"\"\"\n",
    "        if self.cuts is None:\n",
    "            raise ValueError(\"Cuts have not been optimized yet. Call optimize_cuts() first.\")\n",
    "            \n",
    "        if self.variable_names is None:\n",
    "            raise ValueError(\"Variable names not set. Call optimize_cuts() first.\")\n",
    "            \n",
    "        mask = self.apply_cuts(df)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        efficiency = self._calculate_efficiency(df, label_column, self.cuts, self.variable_names, signal_class)\n",
    "        background_rejection = self._calculate_background_rejection(df, label_column, self.cuts, self.variable_names, signal_class)\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        signal_mask = df[label_column] == signal_class\n",
    "        background_mask = df[label_column] != signal_class\n",
    "        \n",
    "        signal_total = signal_mask.sum()\n",
    "        background_total = background_mask.sum()\n",
    "        signal_passed = (mask & signal_mask).sum()\n",
    "        background_passed = (mask & background_mask).sum()\n",
    "        \n",
    "        results = {\n",
    "            'efficiency': efficiency,\n",
    "            'background_rejection': background_rejection,\n",
    "            'signal_total': signal_total,\n",
    "            'signal_passed': signal_passed,\n",
    "            'background_total': background_total,\n",
    "            'background_passed': background_passed,\n",
    "            'overall_acceptance': mask.sum() / len(mask),\n",
    "            'cuts': dict(zip(self.variable_names, self.cuts))\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c134a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cutbased_tight = SequentialCuts(target_efficiency=0.9, optimization_method='powell', verbose=True)\n",
    "m_cutbased_tight.optimize_cuts(m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)], \n",
    "                         variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'], \n",
    "                         label_column='target', signal_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f72050",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cutbased_medium = SequentialCuts(target_efficiency=0.95, optimization_method='powell', verbose=True)\n",
    "m_cutbased_medium.optimize_cuts(m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)], \n",
    "                         variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'], \n",
    "                         label_column='target', signal_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb809bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_cutbased_loose = SequentialCuts(target_efficiency=0.99, optimization_method='powell', verbose=True)\n",
    "m_cutbased_loose.optimize_cuts(m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)], \n",
    "                         variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'], \n",
    "                         label_column='target', signal_class=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8436e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class NeuralNetworkClassifier:\n",
    "    \"\"\"\n",
    "    A Neural Network classifier that can be tuned to achieve a target efficiency for a given class.\n",
    "    \n",
    "    This class trains a simple NN and finds the optimal threshold to achieve the target efficiency\n",
    "    while maximizing background rejection.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, target_efficiency=0.9, hidden_layers=[64, 32], dropout_rate=0.2, \n",
    "                 learning_rate=0.001, epochs=100, batch_size=256, verbose=True):\n",
    "        \"\"\"\n",
    "        Initialize the Neural Network classifier.\n",
    "        \n",
    "        Args:\n",
    "            target_efficiency (float): Target efficiency for the signal class (0-1).\n",
    "            hidden_layers (list): List of hidden layer sizes.\n",
    "            dropout_rate (float): Dropout rate for regularization.\n",
    "            learning_rate (float): Learning rate for Adam optimizer.\n",
    "            epochs (int): Maximum number of training epochs.\n",
    "            batch_size (int): Batch size for training.\n",
    "            verbose (bool): Whether to print training progress.\n",
    "        \"\"\"\n",
    "        self.target_efficiency = target_efficiency\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.model = None\n",
    "        self.scaler = None\n",
    "        self.threshold = None\n",
    "        self.efficiency_achieved = None\n",
    "        self.background_rejection = None\n",
    "        self.variable_names = None\n",
    "        \n",
    "    def _build_model(self, input_dim):\n",
    "        \"\"\"\n",
    "        Build the neural network model.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Number of input features.\n",
    "            \n",
    "        Returns:\n",
    "            tf.keras.Model: Compiled neural network model.\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer\n",
    "        model.add(Dense(self.hidden_layers[0], input_dim=input_dim, activation='relu'))\n",
    "        model.add(Dropout(self.dropout_rate))\n",
    "        \n",
    "        # Hidden layers\n",
    "        for layer_size in self.hidden_layers[1:]:\n",
    "            model.add(Dense(layer_size, activation='relu'))\n",
    "            model.add(Dropout(self.dropout_rate))\n",
    "        \n",
    "        # Output layer\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        # Compile model\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=self.learning_rate),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def _find_optimal_threshold(self, y_true, y_pred_proba, signal_class=1):\n",
    "        \"\"\"\n",
    "        Find the optimal threshold to achieve target efficiency.\n",
    "        \n",
    "        Args:\n",
    "            y_true (np.array): True labels.\n",
    "            y_pred_proba (np.array): Predicted probabilities.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            float: Optimal threshold.\n",
    "        \"\"\"\n",
    "        # Get ROC curve\n",
    "        fpr, tpr, thresholds = roc_curve(y_true == signal_class, y_pred_proba)\n",
    "        \n",
    "        # Find threshold closest to target efficiency\n",
    "        target_idx = np.argmin(np.abs(tpr - self.target_efficiency))\n",
    "        optimal_threshold = thresholds[target_idx]\n",
    "        \n",
    "        achieved_efficiency = tpr[target_idx]\n",
    "        background_rejection = 1 - fpr[target_idx]\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Optimal threshold: {optimal_threshold:.4f}\")\n",
    "            print(f\"Achieved efficiency: {achieved_efficiency:.4f}\")\n",
    "            print(f\"Background rejection: {background_rejection:.4f}\")\n",
    "            print(f\"False Alarm: {fpr[target_idx]:.4f}\")\n",
    "        \n",
    "        return optimal_threshold, achieved_efficiency, background_rejection\n",
    "    \n",
    "    def train_and_optimize(self, df, variable_names, label_column, signal_class=1, \n",
    "                          test_size=0.2, validation_split=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Train the neural network and find optimal threshold.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            variable_names (list): List of variable names to use as features.\n",
    "            label_column (str): Name of the label column.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            test_size (float): Fraction of data to use for testing.\n",
    "            validation_split (float): Fraction of training data to use for validation.\n",
    "            random_state (int): Random state for reproducibility.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Training history and performance metrics.\n",
    "        \"\"\"\n",
    "        # Check if columns exist\n",
    "        missing_cols = [col for col in variable_names + [label_column] if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "        \n",
    "        self.variable_names = variable_names\n",
    "        \n",
    "        # Prepare data\n",
    "        X = df[variable_names].values\n",
    "        y = (df[label_column] == signal_class).astype(int).values\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Scale features\n",
    "        self.scaler = StandardScaler()\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"Training on {len(variable_names)} features: {variable_names}\")\n",
    "            print(f\"Training samples: {len(X_train)} (Signal: {y_train.sum()}, Background: {len(y_train) - y_train.sum()})\")\n",
    "            print(f\"Test samples: {len(X_test)} (Signal: {y_test.sum()}, Background: {len(y_test) - y_test.sum()})\")\n",
    "        \n",
    "        # Build and train model\n",
    "        self.model = self._build_model(len(variable_names))\n",
    "        \n",
    "        # Early stopping callback\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1 if self.verbose else 0\n",
    "        )\n",
    "        \n",
    "        # Train model\n",
    "        history = self.model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=self.epochs,\n",
    "            batch_size=self.batch_size,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=1 if self.verbose else 0\n",
    "        )\n",
    "        \n",
    "        # Get predictions on test set\n",
    "        y_pred_proba = self.model.predict(X_test_scaled, verbose=0).flatten()\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        self.threshold, self.efficiency_achieved, self.background_rejection = \\\n",
    "            self._find_optimal_threshold(y_test, y_pred_proba, signal_class)\n",
    "        \n",
    "        return {\n",
    "            'history': history.history,\n",
    "            'test_efficiency': self.efficiency_achieved,\n",
    "            'test_background_rejection': self.background_rejection,\n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "    \n",
    "    def predict_proba(self, df):\n",
    "        \"\"\"\n",
    "        Predict probabilities for new data.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            \n",
    "        Returns:\n",
    "            np.array: Predicted probabilities.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained yet. Call train_and_optimize() first.\")\n",
    "        \n",
    "        if self.scaler is None:\n",
    "            raise ValueError(\"Scaler not fitted. Call train_and_optimize() first.\")\n",
    "        \n",
    "        if self.variable_names is None:\n",
    "            raise ValueError(\"Variable names not set. Call train_and_optimize() first.\")\n",
    "        \n",
    "        # Check if columns exist\n",
    "        missing_cols = [col for col in self.variable_names if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns in DataFrame: {missing_cols}\")\n",
    "        \n",
    "        X = df[self.variable_names].values\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        return self.model.predict(X_scaled, verbose=0).flatten()\n",
    "    \n",
    "    def apply_cuts(self, df):\n",
    "        \"\"\"\n",
    "        Apply the optimized threshold to data.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            \n",
    "        Returns:\n",
    "            pd.Series: Boolean mask indicating which samples pass the cuts.\n",
    "        \"\"\"\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Threshold has not been optimized yet. Call train_and_optimize() first.\")\n",
    "        \n",
    "        probabilities = self.predict_proba(df)\n",
    "        return probabilities > self.threshold\n",
    "    \n",
    "    def evaluate_cuts(self, df, label_column, signal_class=1):\n",
    "        \"\"\"\n",
    "        Evaluate the performance of the model on new data.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Input DataFrame.\n",
    "            label_column (str): Name of the label column.\n",
    "            signal_class (int): Label value for signal class.\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing efficiency, background rejection, and other metrics.\n",
    "        \"\"\"\n",
    "        if self.threshold is None:\n",
    "            raise ValueError(\"Model has not been trained yet. Call train_and_optimize() first.\")\n",
    "        \n",
    "        mask = self.apply_cuts(df)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        signal_mask = df[label_column] == signal_class\n",
    "        background_mask = df[label_column] != signal_class\n",
    "        \n",
    "        signal_total = signal_mask.sum()\n",
    "        background_total = background_mask.sum()\n",
    "        signal_passed = (mask & signal_mask).sum()\n",
    "        background_passed = (mask & background_mask).sum()\n",
    "        \n",
    "        efficiency = signal_passed / signal_total if signal_total > 0 else 0.0\n",
    "        background_rejection = 1.0 - (background_passed / background_total) if background_total > 0 else 1.0\n",
    "        \n",
    "        results = {\n",
    "            'efficiency': efficiency,\n",
    "            'background_rejection': background_rejection,\n",
    "            'false_alarm': 1.0 - background_rejection,\n",
    "            'signal_total': signal_total,\n",
    "            'signal_passed': signal_passed,\n",
    "            'background_total': background_total,\n",
    "            'background_passed': background_passed,\n",
    "            'overall_acceptance': mask.sum() / len(mask),\n",
    "            'threshold': self.threshold,\n",
    "            'features_used': self.variable_names\n",
    "        }\n",
    "        \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94240ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of Neural Network classifier\n",
    "print(\"=== Neural Network Approach ===\")\n",
    "print()\n",
    "\n",
    "# Create NN classifier for tight working point (90% efficiency)\n",
    "nn_tight = NeuralNetworkClassifier(\n",
    "    target_efficiency=0.9,\n",
    "    hidden_layers=[5],\n",
    "    dropout_rate=0,\n",
    "    learning_rate=0.001,\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training NN for tight working point (90% efficiency)...\")\n",
    "train_results = nn_tight.train_and_optimize(\n",
    "    df=m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)],\n",
    "    variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'],\n",
    "    label_column='target',\n",
    "    signal_class=1,\n",
    "    test_size=0.2,\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Final test efficiency: {train_results['test_efficiency']:.4f}\")\n",
    "print(f\"Final test background rejection: {train_results['test_background_rejection']:.4f}\")\n",
    "print(f\"Optimal threshold: {train_results['threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155f0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN classifier for medium working point (95% efficiency)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training NN for medium working point (95% efficiency)...\")\n",
    "nn_medium = NeuralNetworkClassifier(\n",
    "    target_efficiency=0.95,\n",
    "    hidden_layers=[5],\n",
    "    dropout_rate=0.,\n",
    "    learning_rate=0.001,\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_results_medium = nn_medium.train_and_optimize(\n",
    "    df=m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)],\n",
    "    variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'],\n",
    "    label_column='target',\n",
    "    signal_class=1,\n",
    "    test_size=0.2,\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Medium NN - Test efficiency: {train_results_medium['test_efficiency']:.4f}\")\n",
    "print(f\"Medium NN - Test background rejection: {train_results_medium['test_background_rejection']:.4f}\")\n",
    "\n",
    "# Create NN classifier for loose working point (99% efficiency)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training NN for loose working point (99% efficiency)...\")\n",
    "nn_loose = NeuralNetworkClassifier(\n",
    "    target_efficiency=0.99,\n",
    "    hidden_layers=[5],\n",
    "    dropout_rate=0.,\n",
    "    learning_rate=0.001,\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "train_results_loose = nn_loose.train_and_optimize(\n",
    "    df=m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)],\n",
    "    variable_names=['cl_reta', 'cl_eratio', 'cl_rhad'],\n",
    "    label_column='target',\n",
    "    signal_class=1,\n",
    "    test_size=0.2,\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Loose NN - Test efficiency: {train_results_loose['test_efficiency']:.4f}\")\n",
    "print(f\"Loose NN - Test background rejection: {train_results_loose['test_background_rejection']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3739b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare results between Sequential Cuts and Neural Network approaches\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPARISON: Sequential Cuts vs Neural Network\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_data = m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)]\n",
    "\n",
    "print(\"\\nTIGHT Working Point (90% target efficiency):\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"Sequential Cuts - Efficiency: {m_cutbased_tight.efficiency_achieved:.4f}, Background Rejection: {m_cutbased_tight.background_rejection:.4f}\")\n",
    "print(f\"Neural Network  - Efficiency: {nn_tight.efficiency_achieved:.4f}, Background Rejection: {nn_tight.background_rejection:.4f}\")\n",
    "\n",
    "print(\"\\nMEDIUM Working Point (95% target efficiency):\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"Sequential Cuts - Efficiency: {m_cutbased_medium.efficiency_achieved:.4f}, Background Rejection: {m_cutbased_medium.background_rejection:.4f}\")\n",
    "print(f\"Neural Network  - Efficiency: {nn_medium.efficiency_achieved:.4f}, Background Rejection: {nn_medium.background_rejection:.4f}\")\n",
    "\n",
    "print(\"\\nLOOSE Working Point (99% target efficiency):\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"Sequential Cuts - Efficiency: {m_cutbased_loose.efficiency_achieved:.4f}, Background Rejection: {m_cutbased_loose.background_rejection:.4f}\")\n",
    "print(f\"Neural Network  - Efficiency: {nn_loose.efficiency_achieved:.4f}, Background Rejection: {nn_loose.background_rejection:.4f}\")\n",
    "\n",
    "# Evaluate on the same test data for fair comparison\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATION ON TEST DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test Sequential Cuts\n",
    "seq_tight_results = m_cutbased_tight.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "seq_medium_results = m_cutbased_medium.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "seq_loose_results = m_cutbased_loose.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "\n",
    "# Test Neural Networks\n",
    "nn_tight_results = nn_tight.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "nn_medium_results = nn_medium.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "nn_loose_results = nn_loose.evaluate_cuts(test_data, 'target', signal_class=1)\n",
    "\n",
    "print(f\"\\nTIGHT - Sequential: Eff={seq_tight_results['efficiency']:.4f}, BkgRej={seq_tight_results['background_rejection']:.4f}\")\n",
    "print(f\"TIGHT - Neural Net: Eff={nn_tight_results['efficiency']:.4f}, BkgRej={nn_tight_results['background_rejection']:.4f}\")\n",
    "\n",
    "print(f\"\\nMEDIUM - Sequential: Eff={seq_medium_results['efficiency']:.4f}, BkgRej={seq_medium_results['background_rejection']:.4f}\")\n",
    "print(f\"MEDIUM - Neural Net: Eff={nn_medium_results['efficiency']:.4f}, BkgRej={nn_medium_results['background_rejection']:.4f}\")\n",
    "\n",
    "print(f\"\\nLOOSE - Sequential: Eff={seq_loose_results['efficiency']:.4f}, BkgRej={seq_loose_results['background_rejection']:.4f}\")\n",
    "print(f\"LOOSE - Neural Net: Eff={nn_loose_results['efficiency']:.4f}, BkgRej={nn_loose_results['background_rejection']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ade5d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6eb925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of Neural Network classifier\n",
    "print(\"=== Neural Network Approach ===\")\n",
    "print()\n",
    "\n",
    "# Create NN classifier for tight working point (90% efficiency)\n",
    "nn_tight = NeuralNetworkClassifier(\n",
    "    target_efficiency=0.9,\n",
    "    hidden_layers=[5],\n",
    "    dropout_rate=0,\n",
    "    learning_rate=0.001,\n",
    "    epochs=200,\n",
    "    batch_size=256,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training NN for tight working point (90% efficiency)...\")\n",
    "train_results = nn_tight.train_and_optimize(\n",
    "    df=m_df[(m_df.et_bin == 1) & (m_df.eta_bin == 0)],\n",
    "    variable_names=[f\"cl_ring_{idx}\" for idx in range(100)], #['cl_reta', 'cl_eratio', 'cl_rhad'],\n",
    "    label_column='target',\n",
    "    signal_class=1,\n",
    "    test_size=0.2,\n",
    "    validation_split=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Final test efficiency: {train_results['test_efficiency']:.4f}\")\n",
    "print(f\"Final test background rejection: {train_results['test_background_rejection']:.4f}\")\n",
    "print(f\"Optimal threshold: {train_results['threshold']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ce8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
