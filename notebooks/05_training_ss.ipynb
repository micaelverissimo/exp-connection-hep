{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "943aaa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "repo_path = '/home/micael.verissimo/paper_lzt/exp-connection-hep/'\n",
    "sys.path.insert(0, repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fd39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 03:15:44.209197: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-11 03:15:44.209241: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-11 03:15:44.210265: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-11 03:15:44.215157: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-11 03:15:46.184245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.30/02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-11 03:15:54.616257: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.638136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.638424: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.701223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.701543: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.701755: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.701927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9157 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:00:10.0, compute capability: 7.5\n",
      "2025-07-11 03:15:54.713209: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.713411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.713544: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.713917: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.714055: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.714183: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.714343: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.714474: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-11 03:15:54.714564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9157 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:00:10.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json \n",
    "import time \n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Any, List, Callable, Dict, Union\n",
    "\n",
    "from src.callbacks import sp_index\n",
    "from src.constants import GeV, et_bins, eta_bins\n",
    "from src.decorators import Summary, Reference\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89a75e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "sgn_df = pd.concat([pd.read_parquet(os.path.join(repo_path, f'data/processed/{iname}')) for iname in ['zee_avg250_100k.parquet']], axis=0)\n",
    "bkg_df = pd.concat([pd.read_parquet(os.path.join(repo_path, f'data/processed/{iname}')) for iname in ['jf17_avg250_100k.parquet']], axis=0)\n",
    "\n",
    "m_df = pd.concat([sgn_df, bkg_df], axis=0)\n",
    "m_df = m_df.loc[m_df.cl_eta.abs() <= 2.5]\n",
    "m_df = m_df.loc[m_df.cl_et >= 15000]\n",
    "\n",
    "input_cols = ['cl_reta', 'cl_eratio', 'cl_rhad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3530a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.duplicated().sum()  # check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb648dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "target",
         "rawType": "int32",
         "type": "integer"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "0720e052-ce27-4d5e-977f-16cb04047cb3",
       "rows": [
        [
         "1",
         "121786"
        ],
        [
         "0",
         "113291"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 2
       }
      },
      "text/plain": [
       "target\n",
       "1    121786\n",
       "0    113291\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559569a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing et bin = [15.0, 30[ and eta bin = [0.0, 0.8[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [0.8, 1.37[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [1.37, 1.54[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [2.37, 2.5[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.0, 0.8[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.8, 1.37[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.37, 1.54[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [2.37, 2.5[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.0, 0.8[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.8, 1.37[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.37, 1.54[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [2.37, 2.5[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [15.0, 30[ and eta bin = [2.37, 2.5[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.0, 0.8[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [0.8, 1.37[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.37, 1.54[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [30.0, 50.0[ and eta bin = [2.37, 2.5[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.0, 0.8[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [0.8, 1.37[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.37, 1.54[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [1.54, 2.37[\n",
      "Processing et bin = [50.0, inf[ and eta bin = [2.37, 2.5[\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tot = 0\n",
    "for iet, (l_iet, h_iet) in enumerate(et_bins):\n",
    "    for ieta, (l_ieta, h_ieta) in enumerate(eta_bins):\n",
    "        print(f'Processing et bin = [{l_iet}, {h_iet}[ and eta bin = [{l_ieta}, {h_ieta}[')\n",
    "        m_df.loc[(m_df.cl_et >= l_iet*GeV) & (m_df.cl_et < h_iet*GeV), 'et_bin'] = int(iet)\n",
    "        m_df.loc[(m_df.cl_eta.abs() >= l_ieta) & (m_df.cl_eta.abs() < h_ieta), 'eta_bin'] = int(ieta)\n",
    "        l_samples = len(m_df.loc[(m_df.et_bin == iet) & (m_df.eta_bin == ieta)])\n",
    "        tot += l_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a40f9aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235077, 235077)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(m_df), tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12c0b7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([1., 2., 3., 0., 4.]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_df.et_bin.unique(), m_df.eta_bin.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1599003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm1(data):\n",
    "    norms = np.abs(data.sum(axis=1))\n",
    "    norms[norms == 0] = 1\n",
    "    return data / norms[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f58cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_simple_mlp(input_shape: int, n_layers: int, n_units: int, seed: int=512) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Builds a simple Multi-Layer Perceptron (MLP) model.\n",
    "\n",
    "    Args:\n",
    "        input_shape (int): The number of input features for the model.\n",
    "        n_layers (int): The number of hidden layers in the MLP.\n",
    "        n_units (int): The number of neurons in each hidden layer.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A compiled Keras model with the specified architecture.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.layers.Input(shape=(input_shape,), name='Input')\n",
    "    for ilayer in range(n_layers):\n",
    "        dense = tf.keras.layers.Dense(n_units, activation='relu', name=f'dense_layer_{ilayer}',\n",
    "                                      kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed),\n",
    "                                      bias_initializer='zeros')(inputs if ilayer == 0 else dense)\n",
    "    # classification layer\n",
    "    dense = tf.keras.layers.Dense(1, activation='linear', name='output_for_inference',\n",
    "                                  kernel_initializer=tf.keras.initializers.GlorotUniform(seed=seed),\n",
    "                                  bias_initializer='zeros')(dense) \n",
    "    output = tf.keras.layers.Activation('sigmoid', name='output_for_training')(dense)\n",
    "    model = tf.keras.Model(inputs, output, name=\"model\")\n",
    "    return model\n",
    "\n",
    "def class_weight(target: np.ndarray) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate class weights and sample weights for binary classification.\n",
    "\n",
    "    Args:\n",
    "        target (np.ndarray): Array of binary target labels (e.g., 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: A pandas Series containing sample weights for each instance, \n",
    "                   with the column name 'weight'.\n",
    "    \"\"\"\n",
    "    classes = np.unique(target)\n",
    "    # [-1,1] or [0,1]\n",
    "    weights = compute_class_weight(class_weight='balanced', classes=classes, y=target)\n",
    "    class_weights = {cl: weights[idx] for idx, cl in enumerate(classes)}\n",
    "    sample_weight = np.ones_like(target, dtype=np.float32)\n",
    "    sample_weight[target == 1] = weights[1]\n",
    "    sample_weight[target != 1] = weights[0]\n",
    "    return pd.Series(sample_weight).to_frame('weight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3588c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataframe: pd.DataFrame, input_cols: List[str], target_col: str,\n",
    "                n_folds: int=5,\n",
    "                n_epochs: int=100, \n",
    "                batch_size: int=1024, \n",
    "                seed: int=512,\n",
    "                optimizer: Any=None,  # Changed to None to create fresh optimizers\n",
    "                loss: Any='binary_crossentropy',\n",
    "                decorators: List=[],\n",
    "                patience: int=25,\n",
    "                verbose: bool=True,\n",
    "                save_path: str=os.path.join(repo_path, 'data/models')) -> None:\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    X, y = norm1(dataframe[input_cols].values), dataframe[target_col].values\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "\n",
    "        x_train, y_train = X[train_index], y[train_index]\n",
    "        x_test, y_test   = X[test_index] , y[test_index]\n",
    "    \n",
    "        l_model = build_simple_mlp(input_shape=X.shape[1], n_layers=1, n_units=5, seed=np.random.randint(0, 1000))\n",
    "        \n",
    "        # Create a fresh optimizer instance for each model to avoid state conflicts\n",
    "        if optimizer is None:\n",
    "            # Use legacy Adam optimizer to avoid the variable recognition issue\n",
    "            fresh_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "        else:\n",
    "            # Create a new instance of the same optimizer type\n",
    "            if hasattr(optimizer, 'get_config'):\n",
    "                config = optimizer.get_config()\n",
    "                fresh_optimizer = optimizer.__class__.from_config(config)\n",
    "            else:\n",
    "                # Fallback to legacy Adam\n",
    "                fresh_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001)\n",
    "        \n",
    "        l_model.compile(optimizer=fresh_optimizer, \n",
    "                    loss=loss, \n",
    "                    metrics=['accuracy']\n",
    "                    )\n",
    "        \n",
    "        sp_index_callback = sp_index(validation_data=(x_test, y_test),\n",
    "                                    patience=patience, verbose=False, save_the_best=True)\n",
    "        start = time.time()\n",
    "        history = l_model.fit(x_train, y_train, epochs=n_epochs,\n",
    "            batch_size=batch_size,\n",
    "            verbose=verbose,\n",
    "            validation_data=(x_test, y_test),\n",
    "            sample_weight=class_weight(y_train),\n",
    "            callbacks=[sp_index_callback],\n",
    "            shuffle=True\n",
    "        ).history\n",
    "        \n",
    "        end = time.time()\n",
    "        \n",
    "        # Run decorators with output capture\n",
    "        et_bin = int(dataframe.et_bin.unique()[0])\n",
    "        eta_bin = int(dataframe.eta_bin.unique()[0])\n",
    "        \n",
    "        \n",
    "        for decorator in decorators:\n",
    "            decorator(history , {'model':l_model, 'data':(x_train, y_train),  'data_val':(x_test, y_test) })\n",
    "            \n",
    "        d = { \n",
    "            'history'          : history, \n",
    "            'model'            : json.loads(l_model.to_json()), \n",
    "            'weights'          : l_model.get_weights(),\n",
    "            'folds'            : i,\n",
    "            'model_type'       : 'mlp_ss',\n",
    "            'time_to_train'    : (end-start)}\n",
    "        output = os.path.join(save_path, \n",
    "                              f'ss_model_et{et_bin}_eta{eta_bin}_fold{i}.pkl')\n",
    "        pickle.dump(d, open(output, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bb92fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for et bin = 0 and eta bin = 0\n",
      "Training model for et bin = 0 and eta bin = 1\n",
      "Training model for et bin = 0 and eta bin = 1\n",
      "Training model for et bin = 0 and eta bin = 2\n",
      "Training model for et bin = 0 and eta bin = 2\n",
      "Training model for et bin = 0 and eta bin = 3\n",
      "Training model for et bin = 0 and eta bin = 3\n",
      "Training model for et bin = 0 and eta bin = 4\n",
      "Training model for et bin = 0 and eta bin = 4\n",
      "Training model for et bin = 1 and eta bin = 0\n",
      "Training model for et bin = 1 and eta bin = 0\n",
      "Training model for et bin = 1 and eta bin = 1\n",
      "Training model for et bin = 1 and eta bin = 1\n",
      "Training model for et bin = 1 and eta bin = 2\n",
      "Training model for et bin = 1 and eta bin = 2\n",
      "Training model for et bin = 1 and eta bin = 3\n",
      "Training model for et bin = 1 and eta bin = 3\n",
      "Training model for et bin = 1 and eta bin = 4\n",
      "Training model for et bin = 1 and eta bin = 4\n",
      "Training model for et bin = 2 and eta bin = 0\n",
      "Training model for et bin = 2 and eta bin = 0\n",
      "Training model for et bin = 2 and eta bin = 1\n",
      "Training model for et bin = 2 and eta bin = 1\n",
      "Training model for et bin = 2 and eta bin = 2\n",
      "Training model for et bin = 2 and eta bin = 2\n",
      "Training model for et bin = 2 and eta bin = 3\n",
      "Training model for et bin = 2 and eta bin = 3\n",
      "Training model for et bin = 2 and eta bin = 4\n",
      "Training model for et bin = 2 and eta bin = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 18:54:14.697723: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:14.967369: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:14.967569: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:14.968521: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:14.968680: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:14.968828: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:15.248587: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:15.248823: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:15.248978: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 18:54:15.249102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 648 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:00:10.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "for iet, ieta in itertools.product(range(3), range(5)):\n",
    "        \n",
    "    with open(os.path.join(repo_path, f'data/processed/references_et{iet}_eta{ieta}.json'), 'r') as f:\n",
    "        ref = json.load(f)\n",
    "    \n",
    "    decorators = [Summary(detailed=True, verbose=False), Reference(ref, verbose=False)]\n",
    "    l_data = m_df.loc[(m_df.et_bin == iet) & (m_df.eta_bin == ieta)]\n",
    "    print(f'Training model for et bin = {iet} and eta bin = {ieta}')\n",
    "    train_model(l_data, input_cols=input_cols, target_col='target',\n",
    "                n_folds=5,\n",
    "                n_epochs=1000,\n",
    "                batch_size=512,\n",
    "                seed=512,\n",
    "                optimizer=None,  # Changed to None to use legacy Adam optimizer\n",
    "                loss='binary_crossentropy',\n",
    "                decorators=decorators,\n",
    "                verbose=False,\n",
    "                patience=25,\n",
    "                save_path=os.path.join(repo_path, 'data/models/ss_models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f7aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
